{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR5241 Project4 \n",
    "##  L1 penalized logistic regression + Doubly Robust Estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Low Dimensional data\n",
    "#### Data processing \n",
    "#### 1.1 Create X and Y variables for L1 Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim = pd.read_csv(r'../data/lowDim_dataset.csv')\n",
    "X_low = lowDim.drop(['A','Y'], axis = 1)  \n",
    "y_low = lowDim[['A']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_low, X_test_low, y_train_low, y_test_low = train_test_split(X_low, y_low, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Standardize features\n",
    "- Because the regularization penalty is comprised of the sum of the absolute value of the coefficients, we need to scale the data so the coefficients are all based on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaler object\n",
    "sc = StandardScaler()\n",
    "X_train_low_std = sc.fit_transform(X_train_low)\n",
    "X_test_low_std = sc.transform(X_test_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. L1 penalized logistic regression \n",
    "#### 2.1 Parameter tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1\n",
      "Coefficient of each feature: [[ 0.34419367  0.43238251  0.73102716 -0.15445403  0.          0.13306032\n",
      "   0.          0.26229326  0.          0.33354899 -0.0579125   0.\n",
      "   0.04015877 -0.50944388  0.14782478  0.          0.24494353  0.10429014\n",
      "   0.          0.          0.00275068  0.41842302]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7226890756302521\n",
      "\n",
      "C: 0.95\n",
      "Coefficient of each feature: [[ 3.41394331e-01  4.19164596e-01  7.21203160e-01 -1.47436611e-01\n",
      "   0.00000000e+00  1.30737853e-01  0.00000000e+00  2.60321521e-01\n",
      "   0.00000000e+00  3.21937086e-01 -4.60120791e-02  0.00000000e+00\n",
      "   3.64427152e-02 -5.04450999e-01  1.46549264e-01  0.00000000e+00\n",
      "   2.44899467e-01  1.03654487e-01  0.00000000e+00  0.00000000e+00\n",
      "   2.75226924e-04  4.16449548e-01]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7142857142857143\n",
      "\n",
      "C: 0.9\n",
      "Coefficient of each feature: [[ 0.33881124  0.40536357  0.710973   -0.13966154  0.          0.12831076\n",
      "   0.          0.25802403  0.          0.30950485 -0.03259145  0.\n",
      "   0.0325736  -0.49920694  0.1454971   0.          0.24499852  0.10311769\n",
      "   0.          0.          0.          0.41449432]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7226890756302521\n",
      "\n",
      "C: 0.85\n",
      "Coefficient of each feature: [[ 0.3359445   0.39000054  0.69979816 -0.13118088  0.          0.12565543\n",
      "   0.          0.25544569  0.          0.29562274 -0.01756336  0.\n",
      "   0.02825947 -0.4934795   0.14434147  0.          0.24512695  0.10253804\n",
      "   0.          0.          0.          0.4122485 ]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7142857142857143\n",
      "\n",
      "C: 0.8\n",
      "Coefficient of each feature: [[ 3.32706708e-01  3.72666018e-01  6.87527309e-01 -1.21973538e-01\n",
      "   0.00000000e+00  1.22676749e-01  0.00000000e+00  2.52476736e-01\n",
      "   0.00000000e+00  2.79881924e-01 -6.62033344e-04  0.00000000e+00\n",
      "   2.33917155e-02 -4.87191398e-01  1.42975705e-01  0.00000000e+00\n",
      "   2.45258898e-01  1.01863777e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  4.09619457e-01]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7142857142857143\n",
      "\n",
      "C: 0.75\n",
      "Coefficient of each feature: [[ 0.32962358  0.35548859  0.67249462 -0.11095296  0.          0.11915652\n",
      "   0.          0.24921983  0.          0.2617699   0.          0.\n",
      "   0.01788389 -0.47648083  0.14151253  0.          0.24546268  0.10099029\n",
      "   0.          0.          0.          0.40768679]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7142857142857143\n",
      "\n",
      "C: 0.7\n",
      "Coefficient of each feature: [[ 0.32609161  0.33593257  0.65561729 -0.09880978  0.          0.11504993\n",
      "   0.          0.2454908   0.          0.24084591  0.          0.\n",
      "   0.01162058 -0.46433433  0.13984284  0.          0.24569365  0.09994348\n",
      "   0.          0.          0.          0.40575491]]\n",
      "Training accuracy: 0.7808988764044944\n",
      "Test accuracy: 0.7142857142857143\n",
      "\n",
      "C: 0.65\n",
      "Coefficient of each feature: [[ 0.32206401  0.31343325  0.63661497 -0.08536137  0.          0.11043813\n",
      "   0.          0.24120019  0.          0.21650018  0.          0.\n",
      "   0.0044388  -0.4506722   0.13790229  0.          0.24597552  0.0987406\n",
      "   0.          0.          0.          0.40340272]]\n",
      "Training accuracy: 0.7808988764044944\n",
      "Test accuracy: 0.7226890756302521\n",
      "\n",
      "C: 0.5\n",
      "Coefficient of each feature: [[ 0.30411937  0.21972855  0.55673928 -0.03585458  0.          0.09328532\n",
      "   0.          0.2226778   0.          0.11090756  0.          0.\n",
      "   0.         -0.3941163   0.13047093  0.          0.24573446  0.09409338\n",
      "   0.          0.          0.          0.39401235]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7226890756302521\n",
      "\n",
      "C: 0.3\n",
      "Coefficient of each feature: [[ 0.26161797  0.          0.37023082  0.          0.          0.04792086\n",
      "   0.          0.17005662  0.          0.          0.          0.\n",
      "   0.         -0.25393774  0.11283954  0.          0.23801075  0.07946065\n",
      "   0.          0.         -0.00254375  0.36647894]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7394957983193278\n",
      "\n",
      "C: 0.2\n",
      "Coefficient of each feature: [[ 0.20430604  0.          0.17063776  0.          0.          0.\n",
      "   0.          0.11363676  0.          0.          0.          0.\n",
      "   0.         -0.12348155  0.09258217  0.          0.22296248  0.05639205\n",
      "   0.          0.         -0.01557123  0.32969147]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7394957983193278\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature: [[ 0.0078065   0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.03724226  0.          0.17918742  0.\n",
      "   0.          0.         -0.03739081  0.19610661]]\n",
      "Training accuracy: 0.7696629213483146\n",
      "Test accuracy: 0.7478991596638656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "C = [1, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.5, 0.3, 0.2, 0.1]\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l1', C = c, solver = 'liblinear')\n",
    "    clf.fit(X_train_low, y_train_low)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy:', clf.score(X_train_low_std, y_train_low))\n",
    "    print('Test accuracy:', clf.score(X_test_low_std, y_test_low))\n",
    "    print('')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_l1_low = time.time()\n",
    "# Best: C = 1\n",
    "clf_low = LogisticRegression(penalty='l1', C = 1, solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Calculate propensity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_low.fit(X_low, y_low.values.ravel())\n",
    "ps_low=clf_low.predict_proba(X_low)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Doubly Robust Estimation for ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_low_dim = lowDim.copy()\n",
    "full_low_dim['PS']=pd.Series(ps_low, index=full_low_dim.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviding the low dimensional data into treated and control groups\n",
    "\n",
    "lowDim_treated = lowDim[lowDim['A'] == 1]\n",
    "lowDim_treated = lowDim_treated.reset_index(drop = True)\n",
    "\n",
    "lowDim_control = lowDim[lowDim['A'] == 0]\n",
    "lowDim_control = lowDim_control.reset_index(drop = True)\n",
    "\n",
    "#Fit a regression model to get the estimation of y given T=1 and X \n",
    "X1_low_treated = lowDim_treated.drop(['Y'], axis = 1)\n",
    "y_low_treated = lowDim_treated['Y']\n",
    "lr_low_treated = LinearRegression().fit(X1_low_treated, y_low_treated)\n",
    "\n",
    "# Fit a regression model to get the estimation of y given T=0and X \n",
    "X1_low_control = lowDim_control.drop(['Y'], axis = 1)\n",
    "y_low_control = lowDim_control['Y']\n",
    "lr_low_control = LinearRegression().fit(X1_low_control, y_low_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all covariates and 'A' columns from full dataset\n",
    "X_low_new = full_low_dim.drop(['Y','PS'], axis = 1)\n",
    "m1_low= lr_low_treated.predict(X_low_new)\n",
    "m0_low= lr_low_control.predict(X_low_new)\n",
    "# join m1 and m0 to full_low_dim\n",
    "full_low_dim['m1'] = pd.Series(m1_low, index = full_low_dim.index)\n",
    "full_low_dim['m0'] = pd.Series(m0_low, index = full_low_dim.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRE(full_data):\n",
    "    \n",
    "    n = len(full_data.index)\n",
    "    result1 = 0\n",
    "    result2 = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        result1 = result1 + (full_data['A'][i] * full_data['Y'][i] - (full_data['A'][i] - full_data['PS'][i])*full_data['m1'][i])/full_data['PS'][i]\n",
    "        result2 = result2 + ((1-full_data['A'][i])* full_data['Y'][i] - (full_data['A'][i] - full_data['PS'][i])*full_data['m0'][i])/(1-full_data['PS'][i])\n",
    "        \n",
    "    ETA = 1/n*(result1-result2)\n",
    "    \n",
    "    return ETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.404204395264653"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time_dre_low = time.time()\n",
    "DRE(full_low_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated ATE for low dimensional data is: 2.404204395264653\n",
      "Accuracy of ATE estimation of low dimensional data is: 3.8318241894138794\n",
      "Running time of L1 Logist Regression model on low dimensional data is: 385.05313205718994 s\n",
      "Running time of DRE model on low dimensional data is: 408.0132300853729 s\n"
     ]
    }
   ],
   "source": [
    "print(f'The estimated ATE for low dimensional data is: {DRE(full_low_dim)}')\n",
    "low_acc = abs(DRE(full_low_dim) - 2.5)/2.5 * 100\n",
    "print(f'Accuracy of ATE estimation of low dimensional data is: {low_acc}')\n",
    "l1_time_low = time.time() - start_time_l1_low \n",
    "print(f'Running time of L1 Logist Regression model on low dimensional data is: {l1_time_low} s')\n",
    "dre_time_low = time.time() - start_time_dre_low\n",
    "print(f'Running time of DRE model on low dimensional data is: {dre_time_low} s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  High Dimensional data\n",
    "#### 1. Data processing \n",
    "#### 1.1 Create X and Y variables for L1 Logistic Regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "highDim = pd.read_csv(r'../data/highDim_dataset.csv')\n",
    "X_high = highDim.drop(['A','Y'], axis = 1)\n",
    "y_high = highDim[['A']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_high, X_test_high, y_train_high, y_test_high = train_test_split(X_high, y_high, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_high_std = sc.fit_transform(X_train_high)\n",
    "X_test_high_std = sc.transform(X_test_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. L1 penalized logistic regression \n",
    "#### 2.1 Parameter tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.06\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  1.58998854e-02  7.23769086e-03\n",
      "   1.62599011e-02 -2.35053723e-02  1.71587305e-03  0.00000000e+00\n",
      "   0.00000000e+00 -2.97405672e-02 -2.15553686e-02  2.76897970e-03\n",
      "   6.24692230e-03  6.26328618e-03  7.34428317e-03 -2.82796530e-03\n",
      "  -9.20471166e-05  0.00000000e+00  5.53036570e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -3.42541770e-02  0.00000000e+00  1.16311084e-02\n",
      "   8.36507452e-04  0.00000000e+00  3.47943638e-04 -5.16593493e-03\n",
      "   1.51992704e-05  0.00000000e+00  1.18289213e-02  9.95651111e-03\n",
      "  -6.77358096e-04 -1.10527225e-03  0.00000000e+00  3.58884161e-05\n",
      "  -8.65896264e-03  2.31220853e-02 -3.53815315e-02  5.11373606e-02\n",
      "   5.34869389e-02  0.00000000e+00  0.00000000e+00 -1.74669007e-02\n",
      "   0.00000000e+00  1.61680691e-02 -5.36437751e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -2.40492886e-03  0.00000000e+00\n",
      "  -1.41986192e-03 -6.12455601e-02  0.00000000e+00  2.57996269e-02\n",
      "  -1.02220306e-02  2.80652369e-03  5.06339234e-03  1.94164540e-03\n",
      "   1.43507793e-04 -3.39884314e-03  1.49492403e-03  4.08099978e-03\n",
      "   0.00000000e+00 -9.48688394e-03  2.15922491e-03 -7.67230403e-03\n",
      "   7.43987083e-04 -1.53162040e-03  3.32215080e-03  4.99511850e-04\n",
      "  -4.13807324e-03  6.08682932e-03  0.00000000e+00  0.00000000e+00\n",
      "   5.30658979e-03  0.00000000e+00  1.48559891e-02  0.00000000e+00\n",
      "  -1.48021753e-02  0.00000000e+00 -2.19435159e-02  4.75849371e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.22819894e-02 -1.96157659e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.30584268e-01  8.78017674e-03\n",
      "  -2.55521337e-02  0.00000000e+00  6.77852365e-03 -7.63325523e-03\n",
      "  -5.28342941e-03 -4.30159839e-03  8.64389244e-03  0.00000000e+00\n",
      "   2.09407409e-02 -1.21533012e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.81557157e-03 -5.07103862e-04  1.60997676e-03 -5.52352904e-03\n",
      "   1.47387419e-03  4.75741973e-03  3.45918125e-03  3.22390327e-04\n",
      "   7.20052028e-03  7.90584386e-03 -3.61703443e-03  2.29821756e-03\n",
      "   4.92056900e-03 -1.39666174e-03  1.46406660e-02 -6.38790115e-03\n",
      "   0.00000000e+00  1.70607277e-02 -7.05181031e-03 -3.07104727e-03\n",
      "  -1.07752068e-02  1.00424418e-02 -2.75085478e-03 -1.28507273e-02\n",
      "  -1.64177635e-03 -1.36950628e-02  0.00000000e+00  3.25848290e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.64753190e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  3.04300038e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -8.79903791e-04\n",
      "   5.94679171e-04 -1.80980930e-03  9.59877713e-04 -4.82956178e-03\n",
      "   6.91817642e-03 -5.05094344e-04  2.63811131e-02  0.00000000e+00\n",
      "  -7.25365310e-03 -3.25452497e-02  0.00000000e+00  1.75021604e-02\n",
      "   0.00000000e+00  4.37006963e-03 -1.11222823e-03  2.64114368e-03\n",
      "  -8.07192249e-03 -1.67788419e-02  0.00000000e+00  3.24499801e-03\n",
      "  -1.12609012e-02  1.97714187e-02  0.00000000e+00 -6.86707153e-03\n",
      "   1.92141426e-02 -2.14095189e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.618\n",
      "Test accuracy: 0.606\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.05\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  1.18045120e-02  7.65256882e-03\n",
      "   1.52302588e-02 -2.17855386e-02  1.50073849e-03  0.00000000e+00\n",
      "   0.00000000e+00 -2.84674811e-02 -1.32132008e-02  2.39757515e-03\n",
      "   5.80380925e-03  5.90705681e-03  6.85244169e-03 -2.76855172e-03\n",
      "  -2.28623858e-04  0.00000000e+00  2.16600147e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -3.10507163e-02  0.00000000e+00  9.14646341e-03\n",
      "   8.31477382e-04  0.00000000e+00  3.65764757e-04 -4.80476242e-03\n",
      "   1.43047335e-05  0.00000000e+00  1.10408262e-02  8.93309453e-03\n",
      "  -6.46076032e-04 -1.10664790e-03  0.00000000e+00  1.82147529e-05\n",
      "  -7.31404085e-03  1.92710041e-02 -3.27232850e-02  4.98215262e-02\n",
      "   4.79009362e-02  0.00000000e+00  0.00000000e+00 -1.40950830e-02\n",
      "   0.00000000e+00  1.51795098e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -6.00832801e-02  0.00000000e+00  2.39971039e-02\n",
      "  -9.40717955e-03  2.87318635e-03  5.35174133e-03  1.39287351e-03\n",
      "   3.87699791e-04 -3.68732953e-03  1.57322847e-03  4.38269481e-03\n",
      "   0.00000000e+00 -9.05760253e-03  1.91140999e-03 -6.87398673e-03\n",
      "   6.81693202e-04 -1.36064891e-03  3.04734420e-03  5.22875428e-04\n",
      "  -3.54014398e-03  5.94155634e-03  0.00000000e+00  0.00000000e+00\n",
      "   4.45359569e-03  0.00000000e+00  1.43492203e-02  0.00000000e+00\n",
      "  -6.94814289e-03  0.00000000e+00 -1.39069432e-02  3.44535370e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.18673804e-02 -1.88293528e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.27406727e-01  3.29879272e-03\n",
      "  -2.60289644e-03  0.00000000e+00  5.92546804e-03 -7.50135555e-03\n",
      "  -4.96313959e-03 -3.89747406e-03  8.03014279e-03  0.00000000e+00\n",
      "   1.88875439e-02 -1.02791544e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.85387079e-03  0.00000000e+00  1.82312973e-03 -4.53046441e-03\n",
      "   3.49736827e-04  3.79544301e-03  2.67203092e-03  0.00000000e+00\n",
      "   5.97654101e-03  7.95575137e-03 -3.39770824e-03  1.90420593e-03\n",
      "   4.23144978e-03 -1.48629255e-03  1.33510840e-02 -6.36066188e-03\n",
      "   0.00000000e+00  1.42071945e-02 -6.20159089e-03 -2.88805997e-03\n",
      "  -9.53234224e-03  9.00058692e-03 -1.97606783e-03 -1.10096171e-02\n",
      "   0.00000000e+00 -1.26765374e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.15189197e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.54322819e-04\n",
      "   2.87137810e-04 -2.23987261e-03  1.00769210e-03 -4.57422186e-03\n",
      "   6.53894864e-03 -7.10047953e-04  2.42052729e-02  0.00000000e+00\n",
      "  -6.87305537e-03 -2.95743424e-02  0.00000000e+00  1.73683917e-02\n",
      "   0.00000000e+00  3.40256570e-03 -4.77332727e-04  2.80290468e-03\n",
      "  -6.92939011e-03 -1.61839895e-02  0.00000000e+00  3.09960352e-03\n",
      "  -1.10418360e-02  1.78776189e-02  0.00000000e+00 -6.12650042e-03\n",
      "   1.69669705e-02 -1.86554221e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.6146666666666667\n",
      "Test accuracy: 0.596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.04\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  5.89969185e-03  8.34777373e-03\n",
      "   1.38911179e-02 -1.98955837e-02  1.12773921e-03  0.00000000e+00\n",
      "   0.00000000e+00 -2.68964257e-02 -1.21498317e-03  2.06888460e-03\n",
      "   5.09597473e-03  5.50620121e-03  6.20823667e-03 -2.60280661e-03\n",
      "  -1.25482311e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -2.69271055e-02  0.00000000e+00  6.51347387e-03\n",
      "   8.55908379e-04  0.00000000e+00  3.82432300e-04 -4.44569772e-03\n",
      "   1.34145426e-05  0.00000000e+00  9.30250575e-03  7.04614015e-03\n",
      "  -5.92853903e-04 -1.07582408e-03  0.00000000e+00  1.08708495e-05\n",
      "  -4.78569751e-03  1.26664543e-02 -2.71782509e-02  4.82206320e-02\n",
      "   4.39987153e-02  0.00000000e+00  0.00000000e+00 -7.81296122e-03\n",
      "   0.00000000e+00  1.24695139e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -5.75623009e-02  0.00000000e+00  2.16238275e-02\n",
      "  -8.36662644e-03  3.11770497e-03  5.93437788e-03  5.64467735e-04\n",
      "   4.62408903e-04 -3.68071292e-03  1.80282585e-03  4.74972093e-03\n",
      "   0.00000000e+00 -8.43913130e-03  1.44937705e-03 -6.17143286e-03\n",
      "   5.86560530e-04 -1.49106170e-03  2.59515332e-03  3.87005068e-04\n",
      "  -3.01350179e-03  5.61313784e-03  0.00000000e+00  0.00000000e+00\n",
      "   4.48381573e-03  0.00000000e+00  1.37845314e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.81574247e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.00851582e-02 -1.74999852e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.24150558e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  5.35802903e-03 -7.55482728e-03\n",
      "  -4.51472230e-03 -3.20970545e-03  7.15085590e-03  0.00000000e+00\n",
      "   1.63047104e-02 -8.17803664e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.15636909e-03  0.00000000e+00  2.12128073e-03 -2.86127303e-03\n",
      "   0.00000000e+00  2.28228713e-03  2.20028312e-03  0.00000000e+00\n",
      "   5.28478635e-03  8.11453864e-03 -1.95053855e-03  1.91460965e-03\n",
      "   3.01963150e-03 -1.70027544e-03  1.13791099e-02 -5.78431626e-03\n",
      "   0.00000000e+00  1.15499887e-02 -5.68994900e-03 -2.57769402e-03\n",
      "  -9.04561997e-03  7.67933236e-03 -1.50641340e-03 -9.96164258e-03\n",
      "   0.00000000e+00 -1.09364309e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.15717746e-03 -2.09344728e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.16169669e-04\n",
      "   0.00000000e+00 -2.54281590e-03  4.07699476e-04 -3.94957207e-03\n",
      "   5.90600431e-03 -1.21531887e-03  2.13404219e-02  7.16912754e-05\n",
      "  -6.37136890e-03 -2.63811229e-02  0.00000000e+00  1.72120496e-02\n",
      "   0.00000000e+00  3.05996674e-03 -9.21053789e-05  2.53417588e-03\n",
      "  -5.63375462e-03 -1.54861833e-02  0.00000000e+00  2.47108334e-03\n",
      "  -1.01156145e-02  1.60433321e-02  0.00000000e+00 -4.68300678e-03\n",
      "   1.43955119e-02 -1.59694994e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.608\n",
      "Test accuracy: 0.59\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.03\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  1.68940428e-03  8.79116834e-03\n",
      "   1.09140648e-02 -1.63896424e-02  7.79454360e-04  0.00000000e+00\n",
      "   0.00000000e+00 -2.40263544e-02  0.00000000e+00  1.79459587e-03\n",
      "   4.85049034e-03  5.21183797e-03  5.49701566e-03 -1.99970308e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -2.17162746e-02  0.00000000e+00  3.67672512e-03\n",
      "   8.82528398e-04  0.00000000e+00  4.80814797e-04 -3.92321616e-03\n",
      "   1.24851243e-05  0.00000000e+00  7.67335950e-03  3.57075523e-03\n",
      "  -5.26988265e-04 -1.04568704e-03  0.00000000e+00  1.97127304e-05\n",
      "  -1.64957150e-03  3.03970612e-03 -1.64938937e-02  4.56144205e-02\n",
      "   4.07377499e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  8.82866917e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -5.21622446e-02  0.00000000e+00  1.54515469e-02\n",
      "  -6.65988364e-03  3.06697001e-03  6.78580672e-03  0.00000000e+00\n",
      "   5.15235102e-04 -3.89557108e-03  2.43347030e-03  5.44757788e-03\n",
      "   0.00000000e+00 -7.34767859e-03  1.16134188e-03 -5.05674380e-03\n",
      "   1.78185445e-05 -1.90984468e-03  1.54274145e-03  0.00000000e+00\n",
      "  -2.47504259e-03  4.89503626e-03  0.00000000e+00  0.00000000e+00\n",
      "   4.24837891e-03  0.00000000e+00  1.26290935e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.27133883e-03\n",
      "   0.00000000e+00  0.00000000e+00 -6.17139324e-03 -1.69990789e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.22011509e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  4.22218882e-03 -8.04540997e-03\n",
      "  -3.69613540e-03 -1.90157010e-03  5.73368513e-03  4.12864756e-04\n",
      "   1.20337609e-02 -4.77553006e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.30668975e-03  0.00000000e+00  1.51282545e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.31295761e-03  0.00000000e+00\n",
      "   4.11682489e-03  7.61378366e-03 -3.63549947e-05  1.42796098e-03\n",
      "   5.78640109e-04 -1.25960416e-03  7.70608579e-03 -6.02670211e-03\n",
      "   0.00000000e+00  6.35977894e-03 -4.35369940e-03 -1.81138508e-03\n",
      "  -7.78724690e-03  5.55321765e-03 -3.39909363e-04 -7.51144922e-03\n",
      "   0.00000000e+00 -7.03443693e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -4.87636734e-03 -5.40962050e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.04673398e-04\n",
      "   0.00000000e+00 -3.76609097e-03  0.00000000e+00 -2.69881653e-03\n",
      "   5.01485773e-03 -1.64433548e-03  1.67279069e-02  9.90283957e-04\n",
      "  -4.12752177e-03 -2.37383582e-02  0.00000000e+00  1.62638541e-02\n",
      "   0.00000000e+00  1.51963238e-03  0.00000000e+00  1.29515322e-03\n",
      "  -3.03063432e-03 -1.40682584e-02  0.00000000e+00  1.14454741e-03\n",
      "  -8.16326348e-03  1.42065483e-02  0.00000000e+00 -1.89862185e-03\n",
      "   8.86036099e-03 -1.05787296e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.6086666666666667\n",
      "Test accuracy: 0.604\n",
      "\n",
      "C: 0.02\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  7.71804772e-03\n",
      "   6.48218813e-03 -1.00245721e-02  8.08662363e-04  0.00000000e+00\n",
      "   0.00000000e+00 -1.90244844e-02  0.00000000e+00  1.42686508e-03\n",
      "   4.02382813e-03  4.62357695e-03  3.91086581e-03 -1.43750954e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.33388389e-02  0.00000000e+00  0.00000000e+00\n",
      "   8.83884873e-04  0.00000000e+00  5.09715131e-04 -2.98348519e-03\n",
      "   1.01048733e-05  0.00000000e+00  3.17830808e-03  0.00000000e+00\n",
      "  -4.57492172e-04 -9.99174997e-04  0.00000000e+00  4.24788332e-05\n",
      "   0.00000000e+00  0.00000000e+00 -2.30808066e-03  3.58120968e-02\n",
      "   3.27732693e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  5.65721719e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -4.01790241e-02  0.00000000e+00  7.32827445e-03\n",
      "  -4.57908051e-03  2.86647372e-03  7.00136229e-03  0.00000000e+00\n",
      "   1.29892300e-03 -4.30575010e-03  1.23772260e-03  4.29245200e-03\n",
      "   0.00000000e+00 -6.87664644e-03  0.00000000e+00 -2.46696203e-03\n",
      "   4.43194958e-05 -1.30700792e-03  0.00000000e+00  0.00000000e+00\n",
      "  -8.90302980e-04  3.84120288e-03  0.00000000e+00  0.00000000e+00\n",
      "   3.40161271e-03  0.00000000e+00  1.18152559e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.52842543e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.17268117e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  2.52720562e-03 -7.95727346e-03\n",
      "  -3.15571479e-03 -2.57844140e-04  3.97089392e-03  7.07435843e-04\n",
      "   7.33012823e-03 -1.37513317e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.15307688e-03  0.00000000e+00  2.09636568e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   3.18598798e-03  6.66179372e-03  0.00000000e+00  1.19332090e-03\n",
      "   0.00000000e+00  0.00000000e+00  4.40661662e-03 -5.82843798e-03\n",
      "   0.00000000e+00  0.00000000e+00 -3.39851823e-03 -1.72636574e-03\n",
      "  -5.76458278e-03  2.91827907e-03  0.00000000e+00 -4.10057980e-03\n",
      "   0.00000000e+00 -3.55723317e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -4.40439422e-03  0.00000000e+00 -7.72439271e-04\n",
      "   3.36404958e-03 -7.56417968e-04  9.42531875e-03  7.93468143e-04\n",
      "   0.00000000e+00 -1.76409491e-02 -7.42954149e-04  1.31379406e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.10035286e-02  0.00000000e+00  0.00000000e+00\n",
      "  -5.53009189e-03  1.04231722e-02  0.00000000e+00  0.00000000e+00\n",
      "   1.29762839e-03 -3.03024857e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.6026666666666667\n",
      "Test accuracy: 0.598\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  4.83240528e-03\n",
      "   0.00000000e+00  0.00000000e+00  3.44441850e-04  0.00000000e+00\n",
      "   0.00000000e+00 -7.14826808e-03  0.00000000e+00  0.00000000e+00\n",
      "   3.74189023e-04  2.04889270e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   9.23339777e-04  0.00000000e+00  2.63763501e-04 -1.70413059e-03\n",
      "   6.39455810e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -2.33643890e-04 -7.86559132e-04  0.00000000e+00  1.75814346e-05\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  6.04989762e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.10026790e-02  0.00000000e+00  0.00000000e+00\n",
      "  -1.23174231e-03  2.66266010e-03  5.78042616e-03  0.00000000e+00\n",
      "   2.16396749e-03 -2.23714928e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -6.76110469e-03  0.00000000e+00 -8.43114034e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.26104355e-03  0.00000000e+00  0.00000000e+00\n",
      "   1.14096441e-03  0.00000000e+00  1.09926296e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.39739609e-03\n",
      "   0.00000000e+00  0.00000000e+00 -9.60349494e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  8.19142977e-04 -6.90200894e-03\n",
      "  -9.73065168e-04  0.00000000e+00  2.61041138e-03  0.00000000e+00\n",
      "   2.93327746e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   8.22236142e-04  0.00000000e+00  4.00759222e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  5.60210584e-03  0.00000000e+00  7.23834110e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.84447365e-04\n",
      "   0.00000000e+00  0.00000000e+00 -2.05142597e-03 -6.36513050e-04\n",
      "  -5.18590088e-03  0.00000000e+00  0.00000000e+00 -6.42016964e-05\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.36607233e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -9.41689333e-04  0.00000000e+00  7.50563123e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -5.42256201e-03  0.00000000e+00  0.00000000e+00\n",
      "  -1.39414629e-03  1.98469319e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.5886666666666667\n",
      "Test accuracy: 0.596\n",
      "\n",
      "C: 0.008\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.57324320e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -4.70736204e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  3.13306952e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.89119524e-04  0.00000000e+00  7.98704058e-05 -1.03641223e-03\n",
      "   4.65098297e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -2.21813261e-04 -7.26970496e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.55822786e-03  0.00000000e+00  0.00000000e+00\n",
      "  -3.25393178e-04  2.06303200e-03  5.06284523e-03  0.00000000e+00\n",
      "   2.18029126e-03 -1.39205370e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -5.45482933e-03  0.00000000e+00 -4.07339020e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  4.84369611e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.04625580e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -8.68394747e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.48956743e-03\n",
      "   0.00000000e+00  0.00000000e+00  2.25107151e-03  0.00000000e+00\n",
      "   1.95926932e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   8.53847565e-04  0.00000000e+00  2.70057081e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  4.73817797e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.81282526e-03  0.00000000e+00\n",
      "  -4.58854849e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -8.61654180e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.08869010e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -3.29726431e-03  0.00000000e+00  0.00000000e+00\n",
      "  -5.62377072e-04  3.37272513e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.584\n",
      "Test accuracy: 0.604\n",
      "\n",
      "C: 0.005\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -4.48026202e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   4.50707025e-04  0.00000000e+00 -1.47331519e-04  0.00000000e+00\n",
      "   3.10278062e-07  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -3.22348706e-04 -5.76266776e-04  0.00000000e+00 -5.34822288e-05\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  3.32605242e-03  0.00000000e+00\n",
      "   2.65108747e-03 -4.52462605e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.95335158e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  8.13652830e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.56725001e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.80462672e-03\n",
      "   0.00000000e+00  0.00000000e+00  5.42089651e-04  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   8.44302107e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.74019358e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -9.23666459e-04  0.00000000e+00\n",
      "  -1.63563613e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.25271887e-05  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  2.90718309e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.5826666666666667\n",
      "Test accuracy: 0.612\n",
      "\n",
      "C: 0.001\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -2.00735976e-05  0.00000000e+00 -6.68702206e-04  0.00000000e+00\n",
      "  -5.63874932e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -8.00316983e-04 -3.20983737e-04  0.00000000e+00 -3.69171886e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.70676454e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.5846666666666667\n",
      "Test accuracy: 0.496\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "C = [.06, .05, .04, .03, .02, .01, 0.008, 0.005, 0.001]\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l1', C = c, solver = 'liblinear')\n",
    "    clf.fit(X_train_high, y_train_high)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy:', clf.score(X_train_high_std, y_train_high))\n",
    "    print('Test accuracy:', clf.score(X_test_high_std, y_test_high))\n",
    "    print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best: C = 0.06\n",
    "start_time_l1_high = time.time()\n",
    "clf_high = LogisticRegression(penalty='l1', C = 0.06, solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Calculate propensity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_high.fit(X_high, y_high.values.ravel())\n",
    "ps_high=clf_high.predict_proba(X_high)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Doubly Robust Estimation Algorithm to calculate ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_high_dim= highDim.copy()\n",
    "full_high_dim['PS']=pd.Series(ps_high, index=full_high_dim.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviding the high dimensional data into treated and control groups\n",
    "highDim_treated = highDim[highDim['A'] == 1]\n",
    "highDim_treated = highDim_treated.reset_index(drop = True)\n",
    "\n",
    "highDim_control = highDim[highDim['A'] == 0]\n",
    "highDim_control = highDim_control.reset_index(drop = True)\n",
    "\n",
    "\n",
    "# Fit a regression model to get the estimation of y given T=1 and X \n",
    "X1_high_treated = highDim_treated.drop(['Y'], axis = 1)\n",
    "y_high_treated = highDim_treated['Y']\n",
    "lr_high_treated = LinearRegression().fit(X1_high_treated, y_high_treated)\n",
    "\n",
    "\n",
    "# Fit a regression model to get the estimation of y given T=0 and X \n",
    "X1_high_control = highDim_control.drop(['Y'], axis = 1)\n",
    "y_high_control = highDim_control['Y']\n",
    "lr_high_control = LinearRegression().fit(X1_high_control, y_high_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_high_new = full_high_dim.drop(['Y','PS'], axis = 1)\n",
    "m1_high= lr_high_treated.predict(X_high_new)\n",
    "m0_high= lr_high_control.predict(X_high_new)\n",
    "full_high_dim['m1'] = pd.Series(m1_high, index = full_high_dim.index)\n",
    "full_high_dim['m0'] = pd.Series(m0_high, index = full_high_dim.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0962049953946535"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time_dre_high = time.time()\n",
    "DRE(full_high_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated ATE for low dimensional data is: -3.0962049953946535\n",
      "Accuracy of ATE estimation of low dimensional data is: 3.206833179821785\n",
      "Running time of L1 Logist Regression model on low dimensional data is: 208.83839631080627 s\n",
      "Running time of DRE model on low dimensional data is: 201.6145739555359 s\n"
     ]
    }
   ],
   "source": [
    "print(f'The estimated ATE for low dimensional data is: {DRE(full_high_dim)}')\n",
    "high_acc = (DRE(full_high_dim) - (-3))/(-3) * 100\n",
    "print(f'Accuracy of ATE estimation of low dimensional data is: {high_acc}')\n",
    "l1_time_high = time.time() - start_time_l1_high \n",
    "print(f'Running time of L1 Logist Regression model on low dimensional data is: {l1_time_high} s')\n",
    "dre_time_high = time.time() - start_time_dre_high\n",
    "print(f'Running time of DRE model on low dimensional data is: {dre_time_high} s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(np.array([[l1_time_low, dre_time_low,low_acc], [l1_time_high, dre_time_high,high_acc]]),\n",
    "                   columns=['l1 running time', 'DRE running time', 'Accuracy of ATE'],\n",
    "                            index=['low dim','high dim'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1 running time</th>\n",
       "      <th>DRE running time</th>\n",
       "      <th>Accuracy of ATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>low dim</th>\n",
       "      <td>385.053132</td>\n",
       "      <td>408.013230</td>\n",
       "      <td>3.831824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high dim</th>\n",
       "      <td>208.838396</td>\n",
       "      <td>201.614574</td>\n",
       "      <td>3.206833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          l1 running time  DRE running time  Accuracy of ATE\n",
       "low dim        385.053132        408.013230         3.831824\n",
       "high dim       208.838396        201.614574         3.206833"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
