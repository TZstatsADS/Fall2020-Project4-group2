{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR5241 Project4 \n",
    "##  L1 penalized logistic regression + Doubly Robust Estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "lowDim = pd.read_csv('../data/lowDim_dataset.csv')\n",
    "highDim = pd.read_csv('../data/highDim_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and Y variables from origianal datasets for L1 Logistic Regression \n",
    "def logit_dataset (df):\n",
    "    #all the covariates as X\n",
    "    X = df.drop(['A','Y'], axis = 1)  \n",
    "    y = df[['A']]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaler training features for regression model\n",
    "def std_feature (x_train, x_test):\n",
    "    sc = StandardScaler()\n",
    "    x_train_scaled = sc.fit_transform(x_train)\n",
    "    x_test_scaled = sc.transform(x_test)\n",
    "    return x_train_scaled,  x_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Low Dimensional data\n",
    "#### Data processing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_low = logit_dataset(lowDim)[0]\n",
    "y_low = logit_dataset(lowDim)[1]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_low, X_test_low, y_train_low, y_test_low = train_test_split(X_low, y_low, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "X_train_low_std =std_feature(X_train_low,X_test_low)[0]\n",
    "X_test_low_std = std_feature(X_train_low,X_test_low)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 penalized logistic regression for propencity scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.1}\n",
      "acuracy from cross_validation: 0.7809076682316118\n",
      "Testing accuracy 0.7394957983193278\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.5, 0.4, 0.3, 0.2, 0.25,0.1]}\n",
    "clf = GridSearchCV(LogisticRegression(penalty='l1'), param_grid)\n",
    "clf=LogisticRegression(penalty='l1',solver = 'liblinear')\n",
    "clf_cv=GridSearchCV(clf,param_grid,cv=5)\n",
    "clf_cv.fit(X_train_low_std, y_train_low.values.ravel())\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_cv.best_params_)\n",
    "print(\"acuracy from cross_validation:\",clf_cv.best_score_)\n",
    "print(\"Testing accuracy\",clf_cv.score(X_test_low_std, y_test_low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_l1_low = time.time()\n",
    "# Best: C = 0.1\n",
    "clf_low = LogisticRegression(penalty='l1', C = 0.1, solver = 'liblinear')\n",
    "#Calculate propensity scores\n",
    "clf_low.fit(X_low, y_low.values.ravel())\n",
    "ps_low=clf_low.predict_proba(X_low)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doubly Robust Estimation for ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_low_dim = lowDim.copy()\n",
    "full_low_dim['PS']=pd.Series(ps_low, index=full_low_dim.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviding the low dimensional data into treated and control groups\n",
    "\n",
    "lowDim_treated = lowDim[lowDim['A'] == 1]\n",
    "lowDim_treated = lowDim_treated.reset_index(drop = True)\n",
    "\n",
    "lowDim_control = lowDim[lowDim['A'] == 0]\n",
    "lowDim_control = lowDim_control.reset_index(drop = True)\n",
    "\n",
    "#Fit a regression model to get the estimation of y given T=1 and X \n",
    "X1_low_treated = lowDim_treated.drop(['Y'], axis = 1)\n",
    "y_low_treated = lowDim_treated['Y']\n",
    "lr_low_treated = LinearRegression().fit(X1_low_treated, y_low_treated)\n",
    "\n",
    "# Fit a regression model to get the estimation of y given T=0and X \n",
    "X1_low_control = lowDim_control.drop(['Y'], axis = 1)\n",
    "y_low_control = lowDim_control['Y']\n",
    "lr_low_control = LinearRegression().fit(X1_low_control, y_low_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all covariates and 'A' columns from full dataset\n",
    "X_low_new = full_low_dim.drop(['Y','PS'], axis = 1)\n",
    "m1_low= lr_low_treated.predict(X_low_new)\n",
    "m0_low= lr_low_control.predict(X_low_new)\n",
    "# join m1 and m0 to full_low_dim\n",
    "full_low_dim['m1'] = pd.Series(m1_low, index = full_low_dim.index)\n",
    "full_low_dim['m0'] = pd.Series(m0_low, index = full_low_dim.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRE(full_data):\n",
    "    \n",
    "    n = len(full_data.index)\n",
    "    result1 = 0\n",
    "    result2 = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        result1 = result1 + (full_data['A'][i] * full_data['Y'][i] - (full_data['A'][i] - full_data['PS'][i])*full_data['m1'][i])/full_data['PS'][i]\n",
    "        result2 = result2 + ((1-full_data['A'][i])* full_data['Y'][i] - (full_data['A'][i] - full_data['PS'][i])*full_data['m0'][i])/(1-full_data['PS'][i])\n",
    "        \n",
    "    ETA = 1/n*(result1-result2)\n",
    "    \n",
    "    return ETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_dre_low = time.time()\n",
    "DRE(full_low_dim)\n",
    "low_acc = (DRE(full_low_dim) - 2.5)/2.5 * 100\n",
    "l1_time_low = time.time() - start_time_l1_low \n",
    "dre_time_low = time.time() - start_time_dre_low\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  High Dimensional data\n",
    "#### Data processing \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_high = logit_dataset(highDim)[0]\n",
    "y_high = logit_dataset(highDim)[1]\n",
    "\n",
    "X_train_high, X_test_high, y_train_high, y_test_high = train_test_split(X_high, y_high, test_size=0.25, random_state=0)\n",
    "\n",
    "# Standardize features\n",
    "X_train_high_std =std_feature(X_train_high,X_test_high)[0]\n",
    "X_test_high_std = std_feature(X_train_high,X_test_high)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 penalized logistic regression for propencity scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.04}\n",
      "acuracy from cross_validation: 0.6040000000000001\n",
      "Testing accuracy 0.594\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [.06, .05, .04, .03, .02, .01, 0.008, 0.005, 0.001]}\n",
    "clf = GridSearchCV(LogisticRegression(penalty='l1'), param_grid)\n",
    "clf=LogisticRegression(penalty='l1',solver = 'liblinear')\n",
    "clf_cv=GridSearchCV(clf,param_grid,cv=5)\n",
    "clf_cv.fit(X_train_high_std, y_train_high.values.ravel())\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_cv.best_params_)\n",
    "print(\"acuracy from cross_validation:\",clf_cv.best_score_)\n",
    "print(\"Testing accuracy\",clf_cv.score(X_test_high_std, y_test_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best: C = 0.04\n",
    "start_time_l1_high = time.time()\n",
    "clf_high = LogisticRegression(penalty='l1', C = 0.04, solver = 'liblinear')\n",
    "#Calculate propensity scores\n",
    "clf_high.fit(X_high, y_high.values.ravel())\n",
    "ps_high=clf_high.predict_proba(X_high)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doubly Robust Estimation Algorithm to calculate ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_high_dim= highDim.copy()\n",
    "full_high_dim['PS']=pd.Series(ps_high, index=full_high_dim.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviding the high dimensional data into treated and control groups\n",
    "highDim_treated = highDim[highDim['A'] == 1]\n",
    "highDim_treated = highDim_treated.reset_index(drop = True)\n",
    "\n",
    "highDim_control = highDim[highDim['A'] == 0]\n",
    "highDim_control = highDim_control.reset_index(drop = True)\n",
    "\n",
    "\n",
    "# Fit a regression model to get the estimation of y given T=1 and X \n",
    "X1_high_treated = highDim_treated.drop(['Y'], axis = 1)\n",
    "y_high_treated = highDim_treated['Y']\n",
    "lr_high_treated = LinearRegression().fit(X1_high_treated, y_high_treated)\n",
    "\n",
    "\n",
    "# Fit a regression model to get the estimation of y given T=0 and X \n",
    "X1_high_control = highDim_control.drop(['Y'], axis = 1)\n",
    "y_high_control = highDim_control['Y']\n",
    "lr_high_control = LinearRegression().fit(X1_high_control, y_high_control)\n",
    "\n",
    "#Add m1 and m0 to dataset\n",
    "X_high_new = full_high_dim.drop(['Y','PS'], axis = 1)\n",
    "m1_high= lr_high_treated.predict(X_high_new)\n",
    "m0_high= lr_high_control.predict(X_high_new)\n",
    "full_high_dim['m1'] = pd.Series(m1_high, index = full_high_dim.index)\n",
    "full_high_dim['m0'] = pd.Series(m0_high, index = full_high_dim.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_dre_high = time.time()\n",
    "DRE(full_high_dim)\n",
    "high_acc = (DRE(full_high_dim) - (-3))/(-3) * 100\n",
    "l1_time_high = time.time() - start_time_l1_high \n",
    "dre_time_high = time.time() - start_time_dre_high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(np.array([[l1_time_low, dre_time_low,low_acc], [l1_time_high, dre_time_high,high_acc]]),\n",
    "                   columns=['l1 running time', 'DRE running time', 'Accuracy of ATE'],\n",
    "                            index=['low dim','high dim'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1 running time</th>\n",
       "      <th>DRE running time</th>\n",
       "      <th>Accuracy of ATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>low dim</th>\n",
       "      <td>15.548346</td>\n",
       "      <td>5.928025</td>\n",
       "      <td>5.814338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high dim</th>\n",
       "      <td>65.148969</td>\n",
       "      <td>0.327322</td>\n",
       "      <td>2.747120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          l1 running time  DRE running time  Accuracy of ATE\n",
       "low dim         15.548346          5.928025         5.814338\n",
       "high dim        65.148969          0.327322         2.747120"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
