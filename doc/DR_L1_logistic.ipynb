{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR5241 Project4 \n",
    "## Doubly Robust Estimation + L1 penalized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 penalized logistic regression to calculate propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V176</th>\n",
       "      <th>V177</th>\n",
       "      <th>V178</th>\n",
       "      <th>V179</th>\n",
       "      <th>V180</th>\n",
       "      <th>V181</th>\n",
       "      <th>V182</th>\n",
       "      <th>V183</th>\n",
       "      <th>V184</th>\n",
       "      <th>V185</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.682472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.176546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.195401</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.005454</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.987538</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Y  A  V1  V2  V3  V4  V5  V6  V7    V8  ...  V176  V177  V178  \\\n",
       "0 -11.682472  1   0   1   2  16   3  -1  13 -0.13  ...     5     7     8   \n",
       "1 -13.176546  0   1   1  12  14  14  14  13  0.24  ...    -1    -1    -1   \n",
       "2  -2.195401  1   0   1  21  22  10  10  14  0.27  ...    -1    -1    -1   \n",
       "3  -0.005454  1   1   1   9  20  11   2  10  0.09  ...   -10   -10   -10   \n",
       "4  -1.987538  1   1   1   7  16  16  11   6  0.15  ...    70    70    80   \n",
       "\n",
       "   V179  V180  V181  V182  V183  V184  V185  \n",
       "0     6     8    -1    -1    -1    -1    -1  \n",
       "1    -1    -1    -1    -1    -1    -1    -1  \n",
       "2    -1    -1    -1    -1    -1    -1    -1  \n",
       "3   -10   -10   -10   -10   -10   -10   -10  \n",
       "4    70    80   -10   -10   -10   -10   -10  \n",
       "\n",
       "[5 rows x 187 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "highDim = pd.read_csv(r'C:\\Users\\zlj01\\Documents\\Columbia University\\GR5243\\project 4\\Data\\highDim_dataset.csv')\n",
    "lowDim = pd.read_csv(r'C:\\Users\\zlj01\\Documents\\Columbia University\\GR5243\\project 4\\Data\\lowDim_dataset.csv')\n",
    "\n",
    "# View high dimensional data\n",
    "highDim.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.678858</td>\n",
       "      <td>0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.309683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.842989</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.719547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.108788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.996210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.355899</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.504077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.787813</td>\n",
       "      <td>1</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.81</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.327864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Y  A    V1   V2   V3    V4    V5    V6    V7    V8  ...   V13  V14  \\\n",
       "0  19.678858  0  1.59  0.0  0.0  0.00  0.24  1.35  0.73  2.58  ...  0.12  0.0   \n",
       "1  17.842989  0  0.00  0.0  0.0  0.00  0.00  0.00  0.00  1.62  ...  0.27  0.0   \n",
       "2  22.108788  1  0.00  0.0  0.0  0.00  0.00  0.00  0.00  0.00  ...  0.00  0.0   \n",
       "3  15.355899  0  0.00  0.0  0.0  0.56  0.00  0.00  0.00  0.00  ...  0.00  0.0   \n",
       "4  16.787813  1  1.81  0.0  0.0  0.00  0.00  0.00  0.00  1.81  ...  0.00  0.0   \n",
       "\n",
       "    V15  V16   V17   V18   V19   V20   V21       V22  \n",
       "0  4.55  0.0  1.72  0.00  0.49  0.98  0.00  1.309683  \n",
       "1  4.87  0.0  0.81  0.27  0.27  0.00  0.00  1.719547  \n",
       "2  0.00  0.0  2.12  0.00  0.00  0.00  2.12  0.996210  \n",
       "3  1.12  0.0  0.00  0.00  0.00  0.00  0.00  1.504077  \n",
       "4  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.327864  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View low dimensional data\n",
    "lowDim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X from the features\n",
    "X_high = highDim.drop(['A','Y'], axis = 1)\n",
    "X_low = lowDim.drop(['A','Y'], axis = 1)\n",
    "\n",
    "# Create y from output\n",
    "y_high = highDim[['A']]\n",
    "y_low = lowDim[['A']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split The Data Into Training And Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split The Data Into Training And Test Sets\n",
    "X_train_high, X_test_high, y_train_high, y_test_high = train_test_split(X_high, y_high, test_size=0.25, random_state=0)\n",
    "X_train_low, X_test_low, y_train_low, y_test_low = train_test_split(X_low, y_low, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the regularization penalty is comprised of the sum of the absolute value of the coefficients, we need to scale the data so the coefficients are all based on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# High Dimensional data\n",
    "# Fit the scaler to the training data and transform\n",
    "X_train_high_std = sc.fit_transform(X_train_high)\n",
    "\n",
    "# Apply the scaler to the test data\n",
    "X_test_high_std = sc.transform(X_test_high)\n",
    "\n",
    "# Low Dimensional data\n",
    "# Fit the scaler to the training data and transform\n",
    "X_train_low_std = sc.fit_transform(X_train_low)\n",
    "\n",
    "# Apply the scaler to the test data\n",
    "X_test_low_std = sc.transform(X_test_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit logistic regression with a L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.06\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  1.58979160e-02  7.23276502e-03\n",
      "   1.62670449e-02 -2.35239693e-02  1.71720719e-03  0.00000000e+00\n",
      "   0.00000000e+00 -2.97362984e-02 -2.15658592e-02  2.76705634e-03\n",
      "   6.24389308e-03  6.26603513e-03  7.34374050e-03 -2.82990481e-03\n",
      "  -9.45905799e-05  0.00000000e+00  5.53142877e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -3.42371252e-02  0.00000000e+00  1.16284555e-02\n",
      "   8.36503124e-04  0.00000000e+00  3.48205151e-04 -5.16416214e-03\n",
      "   1.51965544e-05  0.00000000e+00  1.18313289e-02  9.97146165e-03\n",
      "  -6.77867251e-04 -1.10482970e-03  0.00000000e+00  3.57607912e-05\n",
      "  -8.64353277e-03  2.31270759e-02 -3.53992812e-02  5.11322645e-02\n",
      "   5.34814164e-02  0.00000000e+00  0.00000000e+00 -1.74566508e-02\n",
      "   0.00000000e+00  1.61654524e-02 -5.32785880e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -2.40652731e-03  0.00000000e+00\n",
      "  -1.40984931e-03 -6.12624971e-02  0.00000000e+00  2.58041067e-02\n",
      "  -1.03692794e-02  2.65685122e-03  4.92346996e-03  1.78831138e-03\n",
      "   0.00000000e+00 -3.54502558e-03  1.49335311e-03  4.07753151e-03\n",
      "   0.00000000e+00 -9.48118154e-03  2.16520329e-03 -7.67381465e-03\n",
      "   8.92152628e-04 -1.37660783e-03  3.46600592e-03  6.50759662e-04\n",
      "  -3.98684408e-03  6.23202601e-03  0.00000000e+00  0.00000000e+00\n",
      "   5.25680238e-03  0.00000000e+00  1.48642148e-02  0.00000000e+00\n",
      "  -1.47785231e-02  0.00000000e+00 -2.19476279e-02  4.75705677e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.22760377e-02 -1.96342033e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.30571770e-01  8.77675016e-03\n",
      "  -2.55396665e-02  0.00000000e+00  6.77726681e-03 -7.63669716e-03\n",
      "  -5.27689532e-03 -4.30115480e-03  8.64210092e-03  0.00000000e+00\n",
      "   2.09076066e-02 -1.21251396e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.81346825e-03 -5.13803899e-04  1.62544133e-03 -5.52130363e-03\n",
      "   1.46379600e-03  4.75321863e-03  3.45031254e-03  3.28853917e-04\n",
      "   7.18052667e-03  7.90871599e-03 -3.62852896e-03  2.28912933e-03\n",
      "   4.91992338e-03 -1.39068541e-03  1.46293686e-02 -6.38590176e-03\n",
      "   0.00000000e+00  1.70524978e-02 -7.04488679e-03 -3.07751998e-03\n",
      "  -1.07626729e-02  1.00320488e-02 -2.74994288e-03 -1.28304750e-02\n",
      "  -1.59655941e-03 -1.37275810e-02  0.00000000e+00  3.63855151e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.64735434e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  3.03471359e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -8.75793900e-04\n",
      "   5.92377746e-04 -1.80709037e-03  9.64629418e-04 -4.83492415e-03\n",
      "   6.91469390e-03 -5.09943501e-04  2.63736662e-02  0.00000000e+00\n",
      "  -7.25889354e-03 -3.25436450e-02  0.00000000e+00  1.74962760e-02\n",
      "   0.00000000e+00  4.37582008e-03 -1.10065342e-03  2.63498455e-03\n",
      "  -8.07463808e-03 -1.67699441e-02  0.00000000e+00  3.24500949e-03\n",
      "  -1.12653221e-02  1.97746337e-02  0.00000000e+00 -6.86995152e-03\n",
      "   1.92181691e-02 -2.14209470e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.618\n",
      "Test accuracy: 0.606\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.05\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  1.20101237e-02  7.61216592e-03\n",
      "   1.51873448e-02 -2.16570793e-02  1.48903560e-03  0.00000000e+00\n",
      "   0.00000000e+00 -2.84796378e-02 -1.31300781e-02  2.38505662e-03\n",
      "   5.74682060e-03  5.84937233e-03  6.82820588e-03 -2.79755957e-03\n",
      "  -2.46463766e-04  0.00000000e+00  2.11224088e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -3.10436741e-02  0.00000000e+00  9.14771827e-03\n",
      "   8.30229395e-04  0.00000000e+00  3.70060466e-04 -4.80963044e-03\n",
      "   1.43490749e-05  0.00000000e+00  1.10908579e-02  8.73405285e-03\n",
      "  -6.48609527e-04 -1.10614112e-03  0.00000000e+00  1.89119830e-05\n",
      "  -7.27478030e-03  1.93235646e-02 -3.27876996e-02  4.98095383e-02\n",
      "   4.76465718e-02  0.00000000e+00  0.00000000e+00 -1.41826295e-02\n",
      "   0.00000000e+00  1.50042025e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -5.98730678e-02  0.00000000e+00  2.40403352e-02\n",
      "  -9.65028447e-03  2.75442810e-03  5.11739524e-03  1.36682226e-03\n",
      "   1.88196996e-04 -3.74458573e-03  1.56865968e-03  4.43184754e-03\n",
      "   0.00000000e+00 -9.14825271e-03  1.87699158e-03 -6.92832794e-03\n",
      "   8.62896064e-04 -1.27884919e-03  3.30203705e-03  5.64635847e-04\n",
      "  -3.45422890e-03  6.13099313e-03  0.00000000e+00  0.00000000e+00\n",
      "   4.81232972e-03  0.00000000e+00  1.42684184e-02  0.00000000e+00\n",
      "  -6.83023244e-03  0.00000000e+00 -1.37579425e-02  3.44487898e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.16976407e-02 -1.90262027e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.27447300e-01  3.35831216e-03\n",
      "  -2.29429677e-03  0.00000000e+00  5.99185941e-03 -7.53884200e-03\n",
      "  -4.99657391e-03 -4.00653865e-03  8.16510624e-03  0.00000000e+00\n",
      "   1.90006437e-02 -1.03253512e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.86367188e-03  0.00000000e+00  1.58722190e-03 -4.60136369e-03\n",
      "   6.23806084e-04  3.82209186e-03  2.82086656e-03  0.00000000e+00\n",
      "   6.21776632e-03  7.95607818e-03 -3.37856407e-03  2.00642502e-03\n",
      "   4.31535004e-03 -1.58059281e-03  1.35281712e-02 -6.37124293e-03\n",
      "   0.00000000e+00  1.45994660e-02 -6.38852872e-03 -2.78005234e-03\n",
      "  -9.75954364e-03  9.31809885e-03 -2.16013543e-03 -1.15242255e-02\n",
      "   0.00000000e+00 -1.29781826e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.18950692e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.76051821e-04\n",
      "   4.04631455e-04 -2.17843983e-03  8.61504463e-04 -4.53265445e-03\n",
      "   6.51372904e-03 -7.05756303e-04  2.41626945e-02  0.00000000e+00\n",
      "  -6.80148578e-03 -2.95691448e-02  0.00000000e+00  1.75130286e-02\n",
      "   0.00000000e+00  3.31093133e-03 -5.13248195e-04  2.92879093e-03\n",
      "  -7.00365107e-03 -1.63472748e-02  0.00000000e+00  3.12541037e-03\n",
      "  -1.10800563e-02  1.80506128e-02  0.00000000e+00 -6.20607642e-03\n",
      "   1.71728542e-02 -1.88772519e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.614\n",
      "Test accuracy: 0.596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.04\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  5.71170934e-03  8.38690353e-03\n",
      "   1.39217137e-02 -1.99707957e-02  1.14553013e-03  0.00000000e+00\n",
      "   0.00000000e+00 -2.69304721e-02 -1.21077612e-03  2.08924093e-03\n",
      "   5.14426798e-03  5.58084696e-03  6.23241742e-03 -2.58453150e-03\n",
      "  -8.57775717e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -2.68736701e-02  0.00000000e+00  6.53781622e-03\n",
      "   8.59724031e-04  0.00000000e+00  3.81428602e-04 -4.42533171e-03\n",
      "   1.33405011e-05  0.00000000e+00  9.23063425e-03  7.24222652e-03\n",
      "  -5.91125217e-04 -1.07540966e-03  0.00000000e+00  9.78988933e-06\n",
      "  -4.78087077e-03  1.26280138e-02 -2.71249017e-02  4.82029254e-02\n",
      "   4.41839147e-02  0.00000000e+00  0.00000000e+00 -7.70957390e-03\n",
      "   0.00000000e+00  1.26010030e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -5.77493353e-02  0.00000000e+00  2.15600047e-02\n",
      "  -8.53010193e-03  2.81115429e-03  5.71829387e-03  2.23250161e-04\n",
      "   2.68130434e-04 -4.02200757e-03  1.82936784e-03  4.73827225e-03\n",
      "   0.00000000e+00 -8.36374666e-03  1.48490189e-03 -6.07871195e-03\n",
      "   7.88721750e-04 -1.22347032e-03  2.75101189e-03  7.24223942e-04\n",
      "  -2.71354645e-03  5.83189688e-03  0.00000000e+00  0.00000000e+00\n",
      "   4.35269354e-03  0.00000000e+00  1.38241619e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.07894591e-05  1.78681762e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.02181047e-02 -1.72732927e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.24163426e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  5.27606429e-03 -7.53365920e-03\n",
      "  -4.49223006e-03 -3.11200746e-03  7.08153432e-03  0.00000000e+00\n",
      "   1.61981872e-02 -8.13850777e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.13029251e-03  0.00000000e+00  2.26099607e-03 -2.78996521e-03\n",
      "   0.00000000e+00  2.21504598e-03  2.08026970e-03  0.00000000e+00\n",
      "   5.09223007e-03  8.07900432e-03 -2.07118023e-03  1.82483862e-03\n",
      "   2.89380194e-03 -1.64472263e-03  1.12122881e-02 -5.79374048e-03\n",
      "   0.00000000e+00  1.10660160e-02 -5.51106707e-03 -2.64841564e-03\n",
      "  -8.79924457e-03  7.40660754e-03 -1.33435792e-03 -9.41916110e-03\n",
      "   0.00000000e+00 -1.06121406e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.74070596e-03 -1.98740715e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.90171222e-04\n",
      "   1.24649285e-07 -2.65772699e-03  5.16692918e-04 -3.92259509e-03\n",
      "   5.92167019e-03 -1.23791882e-03  2.13143811e-02  2.81064724e-04\n",
      "  -6.41999142e-03 -2.64962630e-02  0.00000000e+00  1.69548480e-02\n",
      "   0.00000000e+00  3.04541623e-03 -2.31875417e-04  2.32873084e-03\n",
      "  -5.59457599e-03 -1.51996292e-02  0.00000000e+00  2.44602172e-03\n",
      "  -1.00072473e-02  1.60118204e-02  0.00000000e+00 -4.64088709e-03\n",
      "   1.40881277e-02 -1.56081279e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.6053333333333333\n",
      "Test accuracy: 0.59\n",
      "\n",
      "C:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.03\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  1.52858230e-03  8.84789584e-03\n",
      "   1.09522539e-02 -1.64465267e-02  7.99223153e-04  0.00000000e+00\n",
      "   0.00000000e+00 -2.40407166e-02  0.00000000e+00  1.79846698e-03\n",
      "   4.89612725e-03  5.27266345e-03  5.50211277e-03 -1.98542449e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -2.16743249e-02  0.00000000e+00  3.74686717e-03\n",
      "   8.86172005e-04  0.00000000e+00  4.79610284e-04 -3.89609240e-03\n",
      "   1.24098926e-05  0.00000000e+00  7.59794513e-03  3.72410949e-03\n",
      "  -5.26500546e-04 -1.04808918e-03  0.00000000e+00  1.98170614e-05\n",
      "  -1.68280182e-03  3.17008865e-03 -1.65395657e-02  4.56289486e-02\n",
      "   4.09546461e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  8.95093212e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -5.22901078e-02  0.00000000e+00  1.54469054e-02\n",
      "  -6.74314600e-03  2.86743738e-03  6.61009664e-03  0.00000000e+00\n",
      "   4.64996344e-04 -4.08615764e-03  2.45940996e-03  5.44370225e-03\n",
      "   0.00000000e+00 -7.34924464e-03  1.17947011e-03 -4.95884461e-03\n",
      "   1.03712229e-04 -1.78019071e-03  1.56503919e-03  1.91240582e-04\n",
      "  -2.36044323e-03  4.99888829e-03  0.00000000e+00  0.00000000e+00\n",
      "   4.01026741e-03  0.00000000e+00  1.27731452e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  4.98540276e-03\n",
      "   0.00000000e+00  0.00000000e+00 -6.30755225e-03 -1.68062625e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.21992584e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  4.14966931e-03 -7.99143850e-03\n",
      "  -3.73935077e-03 -1.81137448e-03  5.65659393e-03  4.36582341e-04\n",
      "   1.20868505e-02 -4.85274435e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.27257673e-03  0.00000000e+00  1.66431716e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.21933950e-03  0.00000000e+00\n",
      "   3.99258731e-03  7.50915181e-03 -1.75810691e-04  1.37817825e-03\n",
      "   5.04929489e-04 -1.18896301e-03  7.59348367e-03 -6.09729124e-03\n",
      "   0.00000000e+00  5.90752459e-03 -4.24020172e-03 -1.87669355e-03\n",
      "  -7.52181754e-03  5.35943719e-03 -1.45909071e-04 -7.04824802e-03\n",
      "   0.00000000e+00 -6.81213246e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.40746969e-03 -4.48582530e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.95823356e-04\n",
      "   0.00000000e+00 -3.77405243e-03  0.00000000e+00 -2.70395066e-03\n",
      "   5.02030354e-03 -1.65138961e-03  1.66838966e-02  1.15013733e-03\n",
      "  -4.14732127e-03 -2.39069230e-02  0.00000000e+00  1.59964729e-02\n",
      "   0.00000000e+00  1.50194261e-03  0.00000000e+00  1.13691619e-03\n",
      "  -3.00768885e-03 -1.37667010e-02  0.00000000e+00  1.07583968e-03\n",
      "  -8.10582832e-03  1.41883495e-02  0.00000000e+00 -1.84567330e-03\n",
      "   8.67381756e-03 -1.03447701e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.608\n",
      "Test accuracy: 0.602\n",
      "\n",
      "C: 0.02\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  7.70109639e-03\n",
      "   6.47491491e-03 -1.00218182e-02  8.00749841e-04  0.00000000e+00\n",
      "   0.00000000e+00 -1.90328599e-02  0.00000000e+00  1.42612726e-03\n",
      "   4.02658927e-03  4.61781164e-03  3.91415841e-03 -1.44542940e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.33338877e-02  0.00000000e+00  0.00000000e+00\n",
      "   8.83949426e-04  0.00000000e+00  5.10958319e-04 -2.98335492e-03\n",
      "   1.01215824e-05  0.00000000e+00  3.14719079e-03  0.00000000e+00\n",
      "  -4.58202513e-04 -9.99583370e-04  0.00000000e+00  4.26434670e-05\n",
      "   0.00000000e+00  0.00000000e+00 -2.27301778e-03  3.57902668e-02\n",
      "   3.27333662e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  5.96301857e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -4.01616779e-02  0.00000000e+00  7.27999697e-03\n",
      "  -4.56945382e-03  2.89537563e-03  6.97591875e-03  0.00000000e+00\n",
      "   1.30682540e-03 -4.31212920e-03  1.24595281e-03  4.26784443e-03\n",
      "   0.00000000e+00 -6.87420969e-03  0.00000000e+00 -2.43778402e-03\n",
      "   3.56151749e-05 -1.31940257e-03  0.00000000e+00  0.00000000e+00\n",
      "  -9.10560431e-04  3.84737851e-03  0.00000000e+00  0.00000000e+00\n",
      "   3.45839930e-03  0.00000000e+00  1.17884069e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.53535235e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.17212845e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  2.55674333e-03 -7.98095308e-03\n",
      "  -3.18444261e-03 -2.72359721e-04  4.00496869e-03  7.24314649e-04\n",
      "   7.17270909e-03 -1.23146451e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.16968218e-03  0.00000000e+00  2.05479073e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   3.30639424e-03  6.66856166e-03  0.00000000e+00  1.22432936e-03\n",
      "   0.00000000e+00  0.00000000e+00  4.46568240e-03 -5.83403564e-03\n",
      "   0.00000000e+00  0.00000000e+00 -3.41360890e-03 -1.70808759e-03\n",
      "  -5.85216876e-03  2.91015481e-03  0.00000000e+00 -4.17610819e-03\n",
      "   0.00000000e+00 -4.22680489e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -4.42903627e-03  0.00000000e+00 -7.45229159e-04\n",
      "   3.34202236e-03 -7.86325821e-04  9.40038990e-03  7.64892976e-04\n",
      "   0.00000000e+00 -1.76273739e-02 -7.04950813e-04  1.31878362e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.10217711e-02  0.00000000e+00  0.00000000e+00\n",
      "  -5.53724299e-03  1.04632031e-02  0.00000000e+00  0.00000000e+00\n",
      "   1.22102712e-03 -2.96308995e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.6026666666666667\n",
      "Test accuracy: 0.598\n",
      "\n",
      "C:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.01\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  4.92511386e-03\n",
      "   0.00000000e+00  0.00000000e+00  3.41505908e-04  0.00000000e+00\n",
      "   0.00000000e+00 -7.14983950e-03  0.00000000e+00  0.00000000e+00\n",
      "   3.71671384e-04  2.04405753e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   9.23076573e-04  0.00000000e+00  2.61514790e-04 -1.70458154e-03\n",
      "   6.38489604e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -2.33804220e-04 -7.85694345e-04  0.00000000e+00  1.81166715e-05\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.98253614e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.09977763e-02  0.00000000e+00  0.00000000e+00\n",
      "  -1.22915712e-03  2.63375884e-03  5.63300124e-03  0.00000000e+00\n",
      "   2.17007132e-03 -2.25029212e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -6.67562437e-03  0.00000000e+00 -8.68672759e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.31929424e-03  0.00000000e+00  0.00000000e+00\n",
      "   1.27391969e-03  0.00000000e+00  1.10286394e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.43903299e-03\n",
      "   0.00000000e+00  0.00000000e+00 -9.59690404e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  8.02933970e-04 -6.85559793e-03\n",
      "  -9.44902256e-04  0.00000000e+00  2.54465614e-03  0.00000000e+00\n",
      "   2.93969948e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   8.20330535e-04  0.00000000e+00  4.01217541e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   9.38204740e-05  5.52207654e-03  0.00000000e+00  7.64225231e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -5.42629243e-04\n",
      "   0.00000000e+00  0.00000000e+00 -2.06097734e-03 -6.31458982e-04\n",
      "  -5.15874637e-03  0.00000000e+00 -9.44349681e-09 -9.40230966e-05\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.34934695e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -9.66165996e-04  0.00000000e+00  7.44765203e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -5.34793977e-03  0.00000000e+00  0.00000000e+00\n",
      "  -1.45164047e-03  1.99470740e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.5886666666666667\n",
      "Test accuracy: 0.596\n",
      "\n",
      "C: 0.008\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.56300131e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -4.70517883e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  3.16626819e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.89092891e-04  0.00000000e+00  7.98981614e-05 -1.03645878e-03\n",
      "   4.64872584e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -2.21533045e-04 -7.26956094e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.55820370e-03  0.00000000e+00  0.00000000e+00\n",
      "  -3.24611975e-04  2.05413445e-03  5.08124463e-03  0.00000000e+00\n",
      "   2.17756683e-03 -1.39486556e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -5.45870074e-03  0.00000000e+00 -4.05445388e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  4.83006267e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.04599207e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -8.68433344e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.49202396e-03\n",
      "   0.00000000e+00  0.00000000e+00  2.25564961e-03  0.00000000e+00\n",
      "   1.95408660e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   8.53131047e-04  0.00000000e+00  2.69893490e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  4.73748278e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.81148989e-03  0.00000000e+00\n",
      "  -4.59245636e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -8.69428866e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.08369422e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -3.29321755e-03  0.00000000e+00  0.00000000e+00\n",
      "  -5.54262643e-04  3.48432640e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.584\n",
      "Test accuracy: 0.604\n",
      "\n",
      "C: 0.005\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -4.45085530e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   4.50870500e-04  0.00000000e+00 -1.51337127e-04  0.00000000e+00\n",
      "   2.87104775e-07  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -3.21685968e-04 -5.72818857e-04  0.00000000e+00 -5.28701093e-05\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  2.48154173e-05  3.24258203e-03  0.00000000e+00\n",
      "   2.65234048e-03 -4.40231188e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.93069275e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  8.17082701e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.56485277e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.77489589e-03\n",
      "   0.00000000e+00  0.00000000e+00  5.20012834e-04  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   8.46538569e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.68803449e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -9.13692957e-04  0.00000000e+00\n",
      "  -1.58299470e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -3.06380750e-06  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  2.72482814e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.5826666666666667\n",
      "Test accuracy: 0.612\n",
      "\n",
      "C: 0.001\n",
      "Coefficient of each feature: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -2.13082279e-05  0.00000000e+00 -6.64876782e-04  0.00000000e+00\n",
      "  -5.63972041e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -8.03001261e-04 -3.19944461e-04  0.00000000e+00 -3.69015555e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.70948883e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "Training accuracy: 0.5846666666666667\n",
      "Test accuracy: 0.496\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "C = [.06, .05, .04, .03, .02, .01, 0.008, 0.005, 0.001]\n",
    "\n",
    "# High Dimensional data\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l1', C = c, solver = 'liblinear')\n",
    "    clf.fit(X_train_high, y_train_high)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy:', clf.score(X_train_high_std, y_train_high))\n",
    "    print('Test accuracy:', clf.score(X_test_high_std, y_test_high))\n",
    "    print('')\n",
    "\n",
    "# Best: C = 0.06\n",
    "clf_high = LogisticRegression(penalty='l1', C = 0.06, solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1\n",
      "Coefficient of each feature: [[ 0.34417019  0.43238324  0.73102525 -0.15445137  0.          0.13306508\n",
      "   0.          0.26229936  0.          0.33353252 -0.05789636  0.\n",
      "   0.04014376 -0.50946271  0.14782053  0.          0.24494551  0.10429296\n",
      "   0.          0.          0.00274624  0.41842793]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7226890756302521\n",
      "\n",
      "C: 0.95\n",
      "Coefficient of each feature: [[ 3.41398945e-01  4.19127909e-01  7.21208155e-01 -1.47451229e-01\n",
      "   0.00000000e+00  1.30765948e-01  0.00000000e+00  2.60289957e-01\n",
      "   0.00000000e+00  3.21900610e-01 -4.60236115e-02  0.00000000e+00\n",
      "   3.64326446e-02 -5.04471427e-01  1.46534933e-01  0.00000000e+00\n",
      "   2.44938544e-01  1.03662850e-01  0.00000000e+00  0.00000000e+00\n",
      "   2.81170568e-04  4.16450228e-01]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7142857142857143\n",
      "\n",
      "C: 0.9\n",
      "Coefficient of each feature: [[ 0.33881442  0.40531854  0.71103734 -0.13969525  0.          0.12834441\n",
      "   0.          0.2579888   0.          0.30951968 -0.03254369  0.\n",
      "   0.03254389 -0.49921483  0.14546122  0.          0.24497915  0.10311857\n",
      "   0.          0.          0.          0.41442894]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7226890756302521\n",
      "\n",
      "C: 0.85\n",
      "Coefficient of each feature: [[ 0.33593413  0.39003189  0.69979025 -0.13117803  0.          0.12565247\n",
      "   0.          0.25544969  0.          0.29561221 -0.01759038  0.\n",
      "   0.02825691 -0.49346704  0.14433663  0.          0.24513465  0.10253733\n",
      "   0.          0.          0.          0.41225898]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7142857142857143\n",
      "\n",
      "C: 0.8\n",
      "Coefficient of each feature: [[ 0.33274948  0.37279521  0.68743049 -0.12191485  0.          0.12268889\n",
      "   0.          0.2525576   0.          0.27993119 -0.00080025  0.\n",
      "   0.02346294 -0.48713715  0.1430398   0.          0.24528628  0.10188521\n",
      "   0.          0.          0.          0.40974877]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7142857142857143\n",
      "\n",
      "C: 0.75\n",
      "Coefficient of each feature: [[ 0.32960295  0.35548661  0.67248299 -0.11094898  0.          0.11911273\n",
      "   0.          0.24924262  0.          0.26175113  0.          0.\n",
      "   0.01789381 -0.4764716   0.14153136  0.          0.24548709  0.10098318\n",
      "   0.          0.          0.          0.40782961]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7142857142857143\n",
      "\n",
      "C: 0.7\n",
      "Coefficient of each feature: [[ 0.32606438  0.33596627  0.65561997 -0.09879343  0.          0.1150305\n",
      "   0.          0.24548395  0.          0.24081872  0.          0.\n",
      "   0.01158435 -0.46437136  0.13980611  0.          0.24572245  0.09994602\n",
      "   0.          0.          0.          0.40569608]]\n",
      "Training accuracy: 0.7808988764044944\n",
      "Test accuracy: 0.7142857142857143\n",
      "\n",
      "C: 0.65\n",
      "Coefficient of each feature: [[ 0.32207363  0.31343498  0.63660425 -0.08536913  0.          0.11043733\n",
      "   0.          0.2411944   0.          0.2165104   0.          0.\n",
      "   0.00443879 -0.45066828  0.13790775  0.          0.24596512  0.0987424\n",
      "   0.          0.          0.          0.40340231]]\n",
      "Training accuracy: 0.7808988764044944\n",
      "Test accuracy: 0.7226890756302521\n",
      "\n",
      "C: 0.5\n",
      "Coefficient of each feature: [[ 0.30410986  0.21971722  0.55676469 -0.03585362  0.          0.09330977\n",
      "   0.          0.22269477  0.          0.1108903   0.          0.\n",
      "   0.         -0.39413686  0.13046455  0.          0.24572902  0.09408972\n",
      "   0.          0.          0.          0.39397918]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7226890756302521\n",
      "\n",
      "C: 0.3\n",
      "Coefficient of each feature: [[ 0.26166591  0.          0.37022362  0.          0.          0.04793936\n",
      "   0.          0.17007336  0.          0.          0.          0.\n",
      "   0.         -0.25398702  0.11289176  0.          0.23798754  0.07946547\n",
      "   0.          0.         -0.00251743  0.36654974]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7394957983193278\n",
      "\n",
      "C: 0.2\n",
      "Coefficient of each feature: [[ 0.20431571  0.          0.17058403  0.          0.          0.\n",
      "   0.          0.11365813  0.          0.          0.          0.\n",
      "   0.         -0.12346193  0.09260591  0.          0.2229576   0.05639383\n",
      "   0.          0.         -0.01555036  0.32972457]]\n",
      "Training accuracy: 0.7837078651685393\n",
      "Test accuracy: 0.7394957983193278\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature: [[ 0.00778078  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.03723129  0.          0.17916721  0.\n",
      "   0.          0.         -0.03741394  0.19604925]]\n",
      "Training accuracy: 0.7696629213483146\n",
      "Test accuracy: 0.7478991596638656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "C = [1, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.5, 0.3, 0.2, 0.1]\n",
    "\n",
    "# Low Dimensional data\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l1', C = c, solver = 'liblinear')\n",
    "    clf.fit(X_train_low, y_train_low)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy:', clf.score(X_train_low_std, y_train_low))\n",
    "    print('Test accuracy:', clf.score(X_test_low_std, y_test_low))\n",
    "    print('')\n",
    "    \n",
    "# Best: C = 1\n",
    "clf_low = LogisticRegression(penalty='l1', C = 1, solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.56218302, 0.34083366, 0.67252103, ..., 0.3389656 , 0.285809  ,\n",
       "       0.54666708])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High dimensional propensity score\n",
    "clf_high.fit(X_high, y_high)\n",
    "clf_high.predict_proba(X_high)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.62068185, 0.4169973 , 0.17205195, 0.14492186, 0.16678062,\n",
       "       0.09433371, 0.2467299 , 0.29488666, 0.08246259, 0.40883861,\n",
       "       0.19978719, 0.26623674, 0.14665718, 0.16206573, 0.599206  ,\n",
       "       0.32875618, 0.44831722, 0.4347246 , 0.25703983, 0.47546671,\n",
       "       0.16082692, 0.22712675, 0.18469108, 0.15766654, 0.29260334,\n",
       "       0.1506285 , 0.10719758, 0.13163903, 0.23334568, 0.37815961,\n",
       "       0.16375794, 0.66316997, 0.28577995, 0.14875151, 0.23686009,\n",
       "       0.15292498, 0.18039204, 0.10881857, 0.18618067, 0.14967025,\n",
       "       0.13090014, 0.39996692, 0.47546671, 0.23323966, 0.66948432,\n",
       "       0.66944362, 0.12396091, 0.1718912 , 0.172     , 0.43697684,\n",
       "       0.15016925, 0.17868689, 0.10285733, 0.15915187, 0.11975   ,\n",
       "       0.13312288, 0.1442913 , 0.62068185, 0.26468956, 0.27442248,\n",
       "       0.09923539, 0.42024931, 0.25881791, 0.23929178, 0.11178088,\n",
       "       0.34253391, 0.51255609, 0.36678315, 0.14278901, 0.13460043,\n",
       "       0.25071981, 0.3504797 , 0.15815588, 0.16299304, 0.06755348,\n",
       "       0.44126991, 0.10824993, 0.19105952, 0.34018776, 0.24375217,\n",
       "       0.11978928, 0.02521136, 0.10871487, 0.53304387, 0.57087417,\n",
       "       0.25087039, 0.91186935, 0.12815676, 0.20461243, 0.25666438,\n",
       "       0.09281579, 0.08679008, 0.31840463, 0.10399804, 0.23866884,\n",
       "       0.36164392, 0.82169843, 0.48760745, 0.02136375, 0.38865156,\n",
       "       0.1589282 , 0.23219386, 0.31296311, 0.41463987, 0.08246259,\n",
       "       0.11573552, 0.1544299 , 0.65262546, 0.1347826 , 0.27812251,\n",
       "       0.25871353, 0.12780551, 0.6847694 , 0.08246259, 0.39952252,\n",
       "       0.13547256, 0.14782712, 0.273035  , 0.1935055 , 0.12614502,\n",
       "       0.30921774, 0.12869837, 0.08246259, 0.12853717, 0.13538767,\n",
       "       0.03013198, 0.20657907, 0.13002506, 0.12266137, 0.09433371,\n",
       "       0.40441519, 0.15901461, 0.13021795, 0.14532365, 0.8009135 ,\n",
       "       0.4821997 , 0.24800453, 0.31242454, 0.2295827 , 0.1506285 ,\n",
       "       0.1162252 , 0.26425774, 0.51500582, 0.37373027, 0.1149336 ,\n",
       "       0.08246259, 0.11608708, 0.15245469, 0.10440255, 0.26475513,\n",
       "       0.186283  , 0.10898638, 0.28911592, 0.44421478, 0.13543398,\n",
       "       0.13798682, 0.19714816, 0.21217052, 0.16503595, 0.33107614,\n",
       "       0.24288869, 0.37249458, 0.12050547, 0.16321371, 0.11187644,\n",
       "       0.44126991, 0.12066252, 0.09923539, 0.1852458 , 0.33410227,\n",
       "       0.11816929, 0.53776716, 0.14317975, 0.29211761, 0.08246259,\n",
       "       0.08246259, 0.12195841, 0.26179886, 0.16878904, 0.31761083,\n",
       "       0.11090734, 0.34920441, 0.42853428, 0.3681903 , 0.25568603,\n",
       "       0.4821455 , 0.10015531, 0.09592634, 0.32047883, 0.08246259,\n",
       "       0.16439737, 0.83128456, 0.08246259, 0.25052479, 0.25314222,\n",
       "       0.13460043, 0.13670195, 0.17911935, 0.13684303, 0.10949583,\n",
       "       0.17590999, 0.09433371, 0.08540687, 0.19164572, 0.06839777,\n",
       "       0.15235494, 0.11837514, 0.11090734, 0.61619528, 0.1318179 ,\n",
       "       0.12502445, 0.27691745, 0.07502546, 0.19874437, 0.31510185,\n",
       "       0.25314222, 0.16906779, 0.30634866, 0.07247316, 0.35357418,\n",
       "       0.17511786, 0.17858415, 0.10015531, 0.09351804, 0.26370094,\n",
       "       0.8548603 , 0.40388462, 0.33824951, 0.44279403, 0.20739455,\n",
       "       0.20835359, 0.21096651, 0.16511534, 0.08246259, 0.23141769,\n",
       "       0.37896598, 0.39263446, 0.09281579, 0.15947295, 0.10366331,\n",
       "       0.13492778, 0.34070332, 0.19350254, 0.1442913 , 0.46122612,\n",
       "       0.24529429, 0.46122612, 0.20306982, 0.11145307, 0.12407394,\n",
       "       0.21232186, 0.20494431, 0.32956756, 0.08246259, 0.36506107,\n",
       "       0.16011867, 0.15152969, 0.45816388, 0.65555042, 0.16054599,\n",
       "       0.19867251, 0.08246259, 0.12256006, 0.09871993, 0.1303687 ,\n",
       "       0.09685123, 0.29391801, 0.12266137, 0.21232186, 0.15959563,\n",
       "       0.65532251, 0.43622227, 0.41463987, 0.10015531, 0.30414805,\n",
       "       0.49328208, 0.37249458, 0.11819328, 0.12501635, 0.16497295,\n",
       "       0.38494844, 0.28685414, 0.12332027, 0.01863598, 0.14849239,\n",
       "       0.27594719, 0.13974103, 0.79842889, 0.08715937, 0.13670658,\n",
       "       0.68793794, 0.264477  , 0.27048097, 0.09221093, 0.11816929,\n",
       "       0.1120376 , 0.19738566, 0.172     , 0.14034468, 0.18809967,\n",
       "       0.18820655, 0.65080218, 0.34980572, 0.13439504, 0.15016925,\n",
       "       0.26798425, 0.34587717, 0.19626352, 0.16126574, 0.08780939,\n",
       "       0.11804795, 0.08347117, 0.13967949, 0.16375794, 0.13693177,\n",
       "       0.34191493, 0.38129297, 0.32935796, 0.13361082, 0.14698531,\n",
       "       0.54792845, 0.30217241, 0.36506107, 0.10638992, 0.34508434,\n",
       "       0.38586239, 0.28349779, 0.16514169, 0.25098854, 0.1996215 ,\n",
       "       0.13131534, 0.15218062, 0.28928454, 0.12476626, 0.14890901,\n",
       "       0.18414539, 0.14171355, 0.05892569, 0.20374311, 0.24259571,\n",
       "       0.18161046, 0.1309871 , 0.08246259, 0.09433371, 0.12355627,\n",
       "       0.24015775, 0.20780596, 0.38440927, 0.16593244, 0.11819328,\n",
       "       0.35885495, 0.40876755, 0.1947203 , 0.30232776, 0.14164344,\n",
       "       0.38761508, 0.20357957, 0.17982618, 0.13203494, 0.24063324,\n",
       "       0.37987007, 0.29439884, 0.16741647, 0.07999541, 0.12064375,\n",
       "       0.28028077, 0.47054616, 0.14613904, 0.41967352, 0.14973697,\n",
       "       0.15199501, 0.16621042, 0.3640603 , 0.21947054, 0.10015531,\n",
       "       0.24622642, 0.17048849, 0.19561554, 0.20433516, 0.41340676,\n",
       "       0.1428291 , 0.12352802, 0.16434162, 0.10015531, 0.13131534,\n",
       "       0.13690613, 0.13929011, 0.23580056, 0.30232776, 0.32749374,\n",
       "       0.25856335, 0.10522626, 0.12476626, 0.30744405, 0.16248929,\n",
       "       0.16738223, 0.21373471, 0.30467453, 0.47840719, 0.13157146,\n",
       "       0.16442131, 0.50191641, 0.52893549, 0.1329598 , 0.14619883,\n",
       "       0.11801139, 0.15915187, 0.2540537 , 0.38626273, 0.13841928,\n",
       "       0.15280667, 0.08246259, 0.41257452, 0.13514163, 0.08881709,\n",
       "       0.25859392, 0.36071736, 0.29101906, 0.08246259, 0.12881557,\n",
       "       0.19873774, 0.47793521, 0.39035125, 0.13204689, 0.49692081,\n",
       "       0.16662713, 0.11819328, 0.14318658, 0.10747947, 0.24697672,\n",
       "       0.13690613, 0.57199429, 0.41158369, 0.4323699 , 0.11037509,\n",
       "       0.19040032, 0.10897509, 0.08679008, 0.12953259, 0.19930701,\n",
       "       0.11056935, 0.15120701, 0.50724301, 0.11895774, 0.08246259,\n",
       "       0.24321616, 0.18382234, 0.35776125, 0.16827484, 0.19669742,\n",
       "       0.21917895, 0.19532243, 0.369973  , 0.24115122, 0.27384116,\n",
       "       0.11557618, 0.43697684, 0.13349359, 0.13628246, 0.16137363,\n",
       "       0.22142769, 0.08455413, 0.07797026, 0.35776125, 0.19451812,\n",
       "       0.41340676, 0.29919993, 0.10685082, 0.49285401, 0.20246485,\n",
       "       0.20541895, 0.21436528, 0.2298268 , 0.4355072 , 0.17746991])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low dimensional propensity score\n",
    "clf_low.fit(X_low, y_low)\n",
    "clf_low.predict_proba(X_low)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
